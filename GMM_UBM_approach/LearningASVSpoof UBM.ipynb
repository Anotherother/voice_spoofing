{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "\n",
    "import ubm_adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_original_train = np.loadtxt('mfcc_original_train.txt')\n",
    "\n",
    "mfcc_spoof_train = np.loadtxt('mfcc_spoof_train.txt')\n",
    "\n",
    "mfcc_original_develop = np.loadtxt('mfcc_original_dev.txt')\n",
    "\n",
    "mfcc_spoof_develop = np.loadtxt('mfcc_spoof_dev.txt')\n",
    "\n",
    "mfcc_original_test = np.loadtxt('mfcc_original_eva.txt')\n",
    "\n",
    "mfcc_spoof_test = np.loadtxt('mfcc_spoof_eva.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([mfcc_original_train, mfcc_spoof_train]) \n",
    "y_train = np.concatenate([np.zeros((mfcc_original_train.shape[0])), np.ones((mfcc_spoof_train.shape[0]))]).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_develop = np.concatenate([mfcc_original_develop, mfcc_spoof_develop]) \n",
    "y_develop = np.concatenate([np.zeros((mfcc_original_develop.shape[0])), np.ones((mfcc_spoof_develop.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.concatenate([mfcc_original_test, mfcc_spoof_test]) \n",
    "y_test = np.concatenate([np.zeros((mfcc_original_test.shape[0])), np.ones((mfcc_spoof_test.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeUBM(ubm_model, data):\n",
    "    ###########################################\n",
    "    # ubm_model - gmm-represent distribution of our model\n",
    "    # data - samples, which will correct ubm-model\n",
    "    ###############################################\n",
    "\n",
    "    xdim = data.shape[1]\n",
    "    M = ubm_model.n_components\n",
    "\n",
    "    ###############################################################\n",
    "    #    ubm_means: means of the ubm <number array>               #\n",
    "    #    ubm_covars: covariances of the ubm <number array>        #\n",
    "    #    ubm_weights: weights of the ubm <number array>           #\n",
    "    #    new_means: means adapted from the ubm <number array>     #\n",
    "    #    new_weights: weights adapted from the ubm <number array> #\n",
    "    ###############################################################\n",
    "\n",
    "    # Copy parameters GMM-model\n",
    "    ubm_weights = ubm_model.weights_\n",
    "    ubm_means = ubm_model.means_\n",
    "    ubm_covars = ubm_model.covars_\n",
    "\n",
    "    ###################################################################\n",
    "    # for X = {x_1, ..., x_T}                                         #\n",
    "    # P(i|x_t) = w_i * p_i(x_t) / sum_j=1_M(w_j * P_j(x_t))           #\n",
    "    ###################################################################\n",
    "\n",
    "    posterior_prob = ubm_model.predict_proba(data)\n",
    "    pr_i_xt = (ubm_weights * posterior_prob) / np.asmatrix(np.sum(ubm_weights \\\n",
    "                                                                  * posterior_prob, axis=1)).T\n",
    "\n",
    "    n_i = np.asarray(np.sum(pr_i_xt, axis=0)).flatten()  # [M, ]\n",
    "\n",
    "    # Then we can compute E(x) and E(x2) and calculate new parameters of\n",
    "    # our model\n",
    "\n",
    "    E_x = np.asarray([(np.asarray(pr_i_xt[:, i]) * data).sum(axis=0) / n_i[i] if not n_i[i] == 0. else np.zeros(xdim) for i in range(M)])  # [M x xdim]\n",
    "    E_x2 = np.asarray([(np.asarray(pr_i_xt[:, i]) * (data ** 2)).sum(axis=0) / n_i[i]  if not n_i[i] == 0. else np.zeros(xdim)for i in range(M)])  # [M x xdim]\n",
    "\n",
    "    ################################################################\n",
    "    #    T: scaling factor, number of samples                      #\n",
    "    #    relevance_factor: factor for scaling the adapted means    #\n",
    "    #    scaleparam - scale parameter for weights matrix estimation#\n",
    "    ################################################################\n",
    "\n",
    "    T = data.shape[0]\n",
    "    relevance_factor = 16\n",
    "    scaleparam = 1\n",
    "\n",
    "    ################################################################\n",
    "    # compute alpha_i: data-depentend apaptation coefficient       #\n",
    "    # alpha_w = alpha_m = alpha_v                                  #\n",
    "    # alpha_i = n_i/ (n_i + relevance factor)                      #\n",
    "    ################################################################\n",
    "\n",
    "    alpha_i = n_i / (n_i + relevance_factor)\n",
    "\n",
    "    ###############################\n",
    "    # Parqameter`s adaptation\n",
    "    ##############################\n",
    "    new_weights = (alpha_i * n_i / T + (1.0 - alpha_i) * ubm_weights) * scaleparam\n",
    "\n",
    "    alpha_i = np.asarray(np.asmatrix(alpha_i).T)\n",
    "    new_means = (alpha_i * E_x + (1. - alpha_i) * ubm_means)\n",
    "    new_covars = alpha_i * E_x2 + (1. - alpha_i) * (ubm_covars + (ubm_means ** 2)) - (new_means ** 2)\n",
    "\n",
    "    #############################################\n",
    "    # if we want compute `full` covariance matrix - comment code here\n",
    "    # new_covars = np.zeros([M, xdim, xdim])\n",
    "    # for j in range(M):\n",
    "    #    new_covars[j] = alpha_i[j]*E_x2[j] +(1. - alpha_i[j]).flatten()*(ubm_covars[j] + (new_means[j]**2))- (ubm_means[j]**2)\n",
    "    #    new_covars[i] = np.where(new_covars[i] < MIN_VARIANCE, MIN_VARIANCE, new_covars[i])\n",
    "    ####################################################################\n",
    "    #   `covars_` : array\n",
    "    #    Covariance parameters for each mixture component.  The shape\n",
    "    #    depends on `covariance_type`::\n",
    "    #        (n_components, n_features)             if 'spherical',\n",
    "    #        (n_features, n_features)               if 'tied',\n",
    "    #        (n_components, n_features)             if 'diag',\n",
    "    #        (n_components, n_features, n_features) if 'full'\n",
    "    #####################################################################\n",
    "\n",
    "    ubm_model.means_ = new_means\n",
    "    ubm_model.weights_ = new_weights\n",
    "    ubm_model.covars_ = new_covars\n",
    "\n",
    "    return ubm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on development set 78.692947613\n"
     ]
    }
   ],
   "source": [
    "n_g = 1024\n",
    "g1 =  GMM(n_components = n_g, covariance_type='diag',init_params='wmc', n_iter=20)\n",
    "g1.fit(mfcc_original_train)\n",
    "\n",
    "g2 =  GMM(n_components = n_g, covariance_type='diag',init_params='wmc', n_iter=20)\n",
    "g2.fit(mfcc_spoof_train)\n",
    "\n",
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1.score(X_develop)  < np.log(mfcc_spoof_train.shape[0])+g2.score(X_develop)).astype('int')\n",
    "\n",
    "accuracy = np.mean(prediction == y_develop) * 100\n",
    "print 'accuracy - prediction on development set', accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on evaluation set 76.8050298856\n"
     ]
    }
   ],
   "source": [
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2.score(X_test)).astype('int')\n",
    "\n",
    "accuracy = np.mean(prediction == y_test) * 100\n",
    "print 'accuracy - prediction on evaluation set', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1_adapt = computeUBM(g1, mfcc_original_develop)\n",
    "g2_adapt = computeUBM(g2, mfcc_spoof_develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on evaluation set. adapted on development 87.720005791\n"
     ]
    }
   ],
   "source": [
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1_adapt.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2_adapt.score(X_test)).astype('int')\n",
    "accuracy = np.mean(prediction == y_test) * 100\n",
    "print 'accuracy - prediction on evaluation set. adapted on development', accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(1,10):\n",
    "    g1_adapt = computeUBM(g1_adapt, mfcc_original_develop)\n",
    "    g2_adapt = computeUBM(g2_adapt, mfcc_spoof_develop)\n",
    "    \n",
    "    prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1_adapt.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2_adapt.score(X_test)).astype('int')\n",
    "    accuracy = np.mean(prediction == y_test) * 100\n",
    "    print accuracy\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "print np.max(acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
