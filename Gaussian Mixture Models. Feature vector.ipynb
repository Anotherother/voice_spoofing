{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.externals.six.moves import xrange\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция генерации MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = 20 \n",
    "\n",
    "def generateMFCC(filename, fileOutput):\n",
    "    (rate,sig) = wav.read(filename)\n",
    "    mfcc_feat = mfcc(sig, rate, numcep = nc)\n",
    "    numOfRow = mfcc_feat.shape[0]\n",
    "    \n",
    "    sum = np.empty([0, mfcc_feat.shape[1]])\n",
    "    sum = np.sum(mfcc_feat, axis = 0)\n",
    "    sum /= numOfRow\n",
    "   \n",
    "    for item in sum:\n",
    "        fileOutput.write(str(item)+',')\n",
    "    \n",
    "    fileOutput.write('\\n')\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_dictors_original_train =  35\n",
    "n_dictors_spoofing_train = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строим вектор признаков для набора дикторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция, принимающая на вход номер первого и последнего диктора,\n",
    "# Дириректорию для входных и выходных данных\n",
    "\n",
    "def model_dictor(start_id, end_id, directory_in, directory_out):\n",
    "    n_samples = 0\n",
    "    \n",
    "    mfcc = []\n",
    "\n",
    "    for j in range(start_id, end_id): \n",
    "        curr_directory = directory_in +  str(j)\n",
    "        files_on_directory = os.listdir(curr_directory)\n",
    "\n",
    "        print 'Generating speaker ' + str(j)+',' , len(files_on_directory), 'samples'\n",
    "\n",
    "        fo = open( directory_out + str(j) + '.csv','w')\n",
    "\n",
    "        for i in range(0, len(files_on_directory) ): \n",
    "            fileName = curr_directory + '\\\\' + files_on_directory[i]\n",
    "            try:\n",
    "                mfcc_res = generateMFCC(fileName, fo)\n",
    "                mfcc.append(mfcc_res) \n",
    "            except:\n",
    "                print \"Error\"\n",
    "        fo.close()\n",
    "    return np.array(mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Извлекаем MFCC для оригинальных дикторов. Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 0, 188 samples\n",
      "Generating speaker 1, 312 samples\n",
      "Generating speaker 2, 347 samples\n",
      "Generating speaker 3, 323 samples\n",
      "Generating speaker 4, 335 samples\n",
      "Generating speaker 5, 359 samples\n",
      "Generating speaker 6, 414 samples\n",
      "Generating speaker 7, 368 samples\n",
      "Generating speaker 8, 329 samples\n",
      "Generating speaker 9, 314 samples\n",
      "Generating speaker 10, 451 samples\n",
      "Generating speaker 11, 298 samples\n",
      "Generating speaker 12, 410 samples\n",
      "Generating speaker 13, 459 samples\n",
      "Generating speaker 14, 334 samples\n",
      "Generating speaker 15, 312 samples\n",
      "Generating speaker 16, 350 samples\n",
      "Generating speaker 17, 377 samples\n",
      "Generating speaker 18, 311 samples\n",
      "Generating speaker 19, 316 samples\n",
      "Generating speaker 20, 474 samples\n",
      "Generating speaker 21, 332 samples\n",
      "Generating speaker 22, 293 samples\n",
      "Generating speaker 23, 437 samples\n",
      "Generating speaker 24, 320 samples\n",
      "Generating speaker 25, 353 samples\n",
      "Generating speaker 26, 335 samples\n",
      "Generating speaker 27, 353 samples\n",
      "Generating speaker 28, 335 samples\n",
      "Generating speaker 29, 275 samples\n",
      "Generating speaker 30, 390 samples\n",
      "Generating speaker 31, 370 samples\n",
      "Generating speaker 32, 479 samples\n",
      "Generating speaker 33, 312 samples\n",
      "Generating speaker 34, 430 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\human\\human\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureOriginal_Train\\\\'\n",
    "\n",
    "start_dictor = 0\n",
    "end_dictor = 35\n",
    "\n",
    "mfcc_original_train = model_dictor(start_dictor,end_dictor,directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_original_train.txt', mfcc_original_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Перемешиваем речевые образцы оригинальных дикторов\n",
    "\n",
    "mfcc_original_train_permutation = np.random.permutation(mfcc_original_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем MFCC для голосовых подделок. Train  set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 0, 1815 samples\n",
      "Generating speaker 1, 1815 samples\n",
      "Generating speaker 2, 1815 samples\n",
      "Generating speaker 3, 1815 samples\n",
      "Generating speaker 4, 1815 samples\n",
      "Generating speaker 5, 1815 samples\n",
      "Generating speaker 6, 1815 samples\n",
      "Generating speaker 7, 1815 samples\n",
      "Generating speaker 8, 1815 samples\n",
      "Generating speaker 9, 1815 samples\n",
      "Generating speaker 10, 1815 samples\n",
      "Generating speaker 11, 1815 samples\n",
      "Generating speaker 12, 1815 samples\n",
      "Generating speaker 13, 1815 samples\n",
      "Generating speaker 14, 1815 samples\n",
      "Generating speaker 15, 1814 samples\n",
      "Generating speaker 16, 1815 samples\n",
      "Generating speaker 17, 1815 samples\n",
      "Generating speaker 18, 1815 samples\n",
      "Generating speaker 19, 1815 samples\n",
      "Generating speaker 20, 1815 samples\n",
      "Generating speaker 21, 1815 samples\n",
      "Generating speaker 22, 1815 samples\n",
      "Generating speaker 23, 1815 samples\n",
      "Generating speaker 24, 1813 samples\n",
      "Generating speaker 25, 1815 samples\n",
      "Generating speaker 26, 1815 samples\n",
      "Generating speaker 27, 1815 samples\n",
      "Generating speaker 28, 1815 samples\n",
      "Generating speaker 29, 1815 samples\n",
      "Generating speaker 30, 1815 samples\n",
      "Generating speaker 31, 1815 samples\n",
      "Generating speaker 32, 1815 samples\n",
      "Generating speaker 33, 1815 samples\n",
      "Generating speaker 34, 1815 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\wav\\Train\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureSpoof_Train\\\\'\n",
    "\n",
    "start_dictor = 0\n",
    "end_dictor = 35\n",
    "\n",
    "mfcc_spoof_train = model_dictor(start_dictor, end_dictor, directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Перемешиваем подделки\n",
    "mfcc_spoof_train_permutation = np.random.permutation(mfcc_spoof_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_spoof_train.txt', mfcc_spoof_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем общий вектор с набором MFCC голосовых подделок и оригинальных образцов. Traint set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([mfcc_original_train_permutation, mfcc_spoof_train_permutation]) \n",
    "# Метки класов\n",
    "y_train = np.concatenate([np.zeros((mfcc_original_train_permutation.shape[0])), np.ones((mfcc_spoof_train_permutation.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем MFCC для оригинальных дикторов. Development Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 35, 350 samples\n",
      "Generating speaker 36, 427 samples\n",
      "Generating speaker 37, 482 samples\n",
      "Generating speaker 38, 306 samples\n",
      "Generating speaker 39, 378 samples\n",
      "Generating speaker 40, 374 samples\n",
      "Generating speaker 41, 364 samples\n",
      "Generating speaker 42, 354 samples\n",
      "Generating speaker 43, 419 samples\n",
      "Generating speaker 44, 411 samples\n",
      "Generating speaker 45, 368 samples\n",
      "Generating speaker 46, 391 samples\n",
      "Generating speaker 47, 465 samples\n",
      "Generating speaker 48, 377 samples\n",
      "Generating speaker 49, 419 samples\n",
      "Generating speaker 50, 417 samples\n",
      "Generating speaker 51, 366 samples\n",
      "Generating speaker 52, 362 samples\n",
      "Generating speaker 53, 416 samples\n",
      "Generating speaker 54, 327 samples\n",
      "Generating speaker 55, 425 samples\n",
      "Generating speaker 56, 382 samples\n",
      "Generating speaker 57, 359 samples\n",
      "Generating speaker 58, 424 samples\n",
      "Generating speaker 59, 380 samples\n",
      "Generating speaker 60, 368 samples\n",
      "Generating speaker 61, 354 samples\n",
      "Generating speaker 62, 380 samples\n",
      "Generating speaker 63, 376 samples\n",
      "Generating speaker 64, 377 samples\n",
      "Generating speaker 65, 361 samples\n",
      "Generating speaker 66, 362 samples\n",
      "Generating speaker 67, 356 samples\n",
      "Generating speaker 68, 367 samples\n",
      "Generating speaker 69, 274 samples\n",
      "Generating speaker 70, 311 samples\n",
      "Generating speaker 71, 380 samples\n",
      "Generating speaker 72, 378 samples\n",
      "Generating speaker 73, 312 samples\n",
      "Generating speaker 74, 377 samples\n",
      "Generating speaker 75, 381 samples\n",
      "Generating speaker 76, 385 samples\n",
      "Generating speaker 77, 380 samples\n",
      "Generating speaker 78, 377 samples\n",
      "Generating speaker 79, 380 samples\n",
      "Generating speaker 80, 379 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\human\\human\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureOriginal_Develop\\\\'\n",
    "\n",
    "start_dictor = 35\n",
    "end_dictor = 81\n",
    "\n",
    "mfcc_original_develop = model_dictor(start_dictor,end_dictor,directory, output_directory)\n",
    "\n",
    "# Перемешиваем речевые образцы оригинальных дикторов\n",
    "mfcc_original_develop_permutation = np.random.permutation(mfcc_original_develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_original_develop.txt', mfcc_original_develop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем MFCC для голосовых подделок. Development Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 0, 4590 samples\n",
      "Generating speaker 1, 4636 samples\n",
      "Generating speaker 2, 4616 samples\n",
      "Generating speaker 3, 4501 samples\n",
      "Generating speaker 4, 4631 samples\n",
      "Generating speaker 5, 4635 samples\n",
      "Generating speaker 6, 4637 samples\n",
      "Generating speaker 7, 4635 samples\n",
      "Generating speaker 8, 4640 samples\n",
      "Generating speaker 9, 4634 samples\n",
      "Generating speaker 10, 4635 samples\n",
      "Generating speaker 11, 4589 samples\n",
      "Generating speaker 12, 4672 samples\n",
      "Generating speaker 13, 4630 samples\n",
      "Generating speaker 14, 4665 samples\n",
      "Generating speaker 15, 4692 samples\n",
      "Generating speaker 16, 4623 samples\n",
      "Generating speaker 17, 4666 samples\n",
      "Generating speaker 18, 4530 samples\n",
      "Generating speaker 19, 4575 samples\n",
      "Generating speaker 20, 4616 samples\n",
      "Generating speaker 21, 4608 samples\n",
      "Generating speaker 22, 4629 samples\n",
      "Generating speaker 23, 4609 samples\n",
      "Generating speaker 24, 4637 samples\n",
      "Generating speaker 25, 4633 samples\n",
      "Generating speaker 26, 4623 samples\n",
      "Generating speaker 27, 4610 samples\n",
      "Generating speaker 28, 4633 samples\n",
      "Generating speaker 29, 4630 samples\n",
      "Generating speaker 30, 4529 samples\n",
      "Generating speaker 31, 4635 samples\n",
      "Generating speaker 32, 4632 samples\n",
      "Generating speaker 33, 4571 samples\n",
      "Generating speaker 34, 4567 samples\n",
      "Generating speaker 35, 4633 samples\n",
      "Generating speaker 36, 4635 samples\n",
      "Generating speaker 37, 4566 samples\n",
      "Generating speaker 38, 4636 samples\n",
      "Generating speaker 39, 4622 samples\n",
      "Generating speaker 40, 4611 samples\n",
      "Generating speaker 41, 4561 samples\n",
      "Generating speaker 42, 4548 samples\n",
      "Generating speaker 43, 4619 samples\n",
      "Generating speaker 44, 4443 samples\n",
      "Generating speaker 45, 4566 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\wav\\Develop\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureSpoof_Develop\\\\'\n",
    "\n",
    "start_dictor = 0\n",
    "end_dictor = 46\n",
    "\n",
    "mfcc_spoof_develop = model_dictor(start_dictor, end_dictor, directory, output_directory)\n",
    "\n",
    "#Перемешиваем подделки\n",
    "mfcc_spoof_develop_permutation = np.random.permutation(mfcc_spoof_develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_spoof_develop.txt', mfcc_spoof_develop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вектор с голосовыми подделками и оригинальными. Метки классов. Develop set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_develop = np.concatenate([mfcc_original_develop_permutation, mfcc_spoof_develop_permutation]) \n",
    "# Делаем метки класов\n",
    "y_develop = np.concatenate([np.zeros((mfcc_original_develop_permutation.shape[0])), np.ones((mfcc_spoof_develop_permutation.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем MFCC для оригинальных дикторов. Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 81, 383 samples\n",
      "Generating speaker 82, 379 samples\n",
      "Generating speaker 83, 382 samples\n",
      "Generating speaker 84, 379 samples\n",
      "Generating speaker 85, 357 samples\n",
      "Generating speaker 86, 380 samples\n",
      "Generating speaker 87, 380 samples\n",
      "Generating speaker 88, 379 samples\n",
      "Generating speaker 89, 380 samples\n",
      "Generating speaker 90, 380 samples\n",
      "Generating speaker 91, 375 samples\n",
      "Generating speaker 92, 382 samples\n",
      "Generating speaker 93, 382 samples\n",
      "Generating speaker 94, 366 samples\n",
      "Generating speaker 95, 348 samples\n",
      "Generating speaker 96, 355 samples\n",
      "Generating speaker 97, 379 samples\n",
      "Generating speaker 98, 379 samples\n",
      "Generating speaker 99, 380 samples\n",
      "Generating speaker 100, 379 samples\n",
      "Generating speaker 101, 379 samples\n",
      "Generating speaker 102, 375 samples\n",
      "Generating speaker 103, 257 samples\n",
      "Generating speaker 104, 380 samples\n",
      "Generating speaker 105, 290 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\human\\human\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureOriginal_Test\\\\'\n",
    "\n",
    "start_dictor = 81\n",
    "end_dictor = 106\n",
    "\n",
    "mfcc_original_test= model_dictor(start_dictor,end_dictor,directory, output_directory)\n",
    "\n",
    "# Перемешиваем речевые образцы оригинальных дикторов\n",
    "mfcc_original_test_permutation = np.random.permutation(mfcc_original_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_original_test.txt', mfcc_original_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем MFCC  для голосовых подделок. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker 0, 655 samples\n",
      "Generating speaker 1, 655 samples\n",
      "Generating speaker 2, 655 samples\n",
      "Generating speaker 3, 655 samples\n",
      "Generating speaker 4, 655 samples\n",
      "Generating speaker 5, 655 samples\n",
      "Generating speaker 6, 655 samples\n",
      "Generating speaker 7, 655 samples\n",
      "Generating speaker 8, 655 samples\n",
      "Generating speaker 9, 655 samples\n",
      "Generating speaker 10, 655 samples\n",
      "Generating speaker 11, 655 samples\n",
      "Generating speaker 12, 655 samples\n",
      "Generating speaker 13, 655 samples\n",
      "Generating speaker 14, 655 samples\n",
      "Generating speaker 15, 655 samples\n",
      "Generating speaker 16, 655 samples\n",
      "Generating speaker 17, 655 samples\n",
      "Generating speaker 18, 655 samples\n",
      "Generating speaker 19, 655 samples\n",
      "Generating speaker 20, 655 samples\n",
      "Generating speaker 21, 655 samples\n",
      "Generating speaker 22, 655 samples\n",
      "Generating speaker 23, 655 samples\n",
      "Generating speaker 24, 655 samples\n"
     ]
    }
   ],
   "source": [
    "directory = r'F:\\Science\\Antispoofing\\AntispoofingDataset\\ASVSpoof2015\\wav\\Test\\\\'\n",
    "output_directory = r'F:\\Science\\Notebook\\01.10.16. Next_step\\FeatureSpoof_Test\\\\'\n",
    "\n",
    "start_dictor = 0\n",
    "end_dictor = 25\n",
    "\n",
    "mfcc_spoof_test = model_dictor(start_dictor, end_dictor, directory, output_directory)\n",
    "\n",
    "#Перемешиваем подделки\n",
    "mfcc_spoof_test_permutation = np.random.permutation(mfcc_spoof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mfcc_spoof_test.txt', mfcc_spoof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.concatenate([mfcc_original_test_permutation, mfcc_spoof_test_permutation]) \n",
    "# Делаем метки класов\n",
    "y_test = np.concatenate([np.zeros((mfcc_original_test_permutation.shape[0])), np.ones((mfcc_spoof_test_permutation.shape[0]))]).astype('int')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
